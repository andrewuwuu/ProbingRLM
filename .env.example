# Minimal setup (recommended)
DSPY_BACKEND=openrouter
OPENROUTER_API_KEY=your_openrouter_api_key_here
DSPY_MODEL=openrouter/free

# Optional: route subagent calls to a different backend/model
# DSPY_SUBAGENT_BACKEND=openrouter
# DSPY_SUBAGENT_MODEL=arcee-ai/trinity-large-preview:free

# Optional DSPy RLM limits
# DSPY_RLM_MAX_ITERATIONS=20
# DSPY_RLM_MAX_LLM_CALLS=40
# DSPY_RLM_MAX_OUTPUT_CHARS=10000
# DSPY_RLM_MAX_DEPTH=3
# DSPY_SUBAGENT_PREFETCH_CALLS=0

# Optional DSPy customization
# DSPY_RLM_SIGNATURE=context, query -> answer
# DSPY_CUSTOM_PROMPT=Prefer concise answers.
# DSPY_OUTPUT_MODE=research  # research | concise
# DSPY_QUERY_TIMEOUT_SECONDS=180
# DSPY_REQUIRE_SUBAGENT_CALL=false
# DSPY_REQUIRE_SUBAGENT_CALL_RETRY_ONCE=false
# DSPY_ENFORCE_PDF_PAGE_CITATIONS=true
# DSPY_RESEARCH_ALLOW_DIRECT_FALLBACK=true
# DSPY_CITATION_REPAIR_DIRECT_MODE=false
# DSPY_OPENROUTER_AUTO_MIDDLE_OUT=true
# DSPY_VERBOSE_METRICS=false
# DSPY_LM_KWARGS={"temperature":0.2}
# DSPY_SUBAGENT_LM_KWARGS={"temperature":0.0}
# DSPY_RLM_INTERPRETER=true
# DSPY_RLM_TOOLS=my_tools.web:search,my_tools.math:calculator

# Optional endpoint overrides (only if you need custom routing)
# DSPY_OPENROUTER_API_BASE=https://openrouter.ai/api/v1
# DSPY_VLLM_BASE_URL=
# DSPY_LITELLM_API_BASE=
# DSPY_LITELLM_API_KEY=
# DSPY_PORTKEY_API_BASE=
# DSPY_VERCEL_API_BASE=

# Other provider keys (set only if you switch DSPY_BACKEND)
# OPENAI_API_KEY=
# ANTHROPIC_API_KEY=
# GEMINI_API_KEY=
# PORTKEY_API_KEY=
# AI_GATEWAY_API_KEY=
# AZURE_OPENAI_API_KEY=

# Azure extras (required only when DSPY_BACKEND=azure_openai)
# AZURE_OPENAI_ENDPOINT=
# AZURE_OPENAI_API_VERSION=2024-02-01
# AZURE_OPENAI_DEPLOYMENT=
